# ğŸ™ï¸ Voice-to-Text Desktop App

A cross-platform desktop application for real-time voice-to-text transcription, built with Tauri and Deepgram. This project is a functional clone of Wispr Flow, focusing on core voice input functionality and clean code architecture.

## âœ¨ Features

- **Push-to-Talk Voice Input**: Intuitive hold-to-record mechanism
- **Real-Time Transcription**: Near-instant speech-to-text using Deepgram's Nova-2 model
- **Cross-Platform**: Works on Windows, macOS, and Linux via Tauri
- **Clean UI**: Simple, functional interface with visual recording feedback
- **Clipboard Integration**: One-click copy transcribed text
- **Error Handling**: Graceful handling of permissions, network issues, and API errors

## ğŸ› ï¸ Tech Stack

- **Desktop Framework**: [Tauri](https://tauri.app/) - Lightweight, secure desktop framework
- **Frontend**: React + TypeScript - Modern UI development
- **Speech-to-Text**: [Deepgram API](https://deepgram.com/) - Industry-leading voice recognition
- **Build Tool**: Vite - Fast development and optimized builds
- **Audio API**: Web Audio API - Browser-native audio capture

## ğŸ“‹ Prerequisites

Before you begin, ensure you have:

1. **Node.js** (v18 or higher)

   ```bash
   node --version
   ```

2. **Rust** (for Tauri)

   ```bash
   curl --proto '=https' --tlsv1.2 -sSf https://sh.rustup.rs | sh
   ```

3. **Deepgram API Key**

   - Sign up at [console.deepgram.com](https://console.deepgram.com/)
   - Free tier includes $200 credit (50,000 minutes)

4. **System Dependencies** (platform-specific)

   **macOS**:

   ```bash
   xcode-select --install
   ```

   **Windows**:

   - Install [Microsoft Visual Studio C++ Build Tools](https://visualstudio.microsoft.com/visual-cpp-build-tools/)
   - Install [WebView2](https://developer.microsoft.com/en-us/microsoft-edge/webview2/)

   **Linux (Debian/Ubuntu)**:

   ```bash
   sudo apt update
   sudo apt install libwebkit2gtk-4.1-dev \
     build-essential \
     curl \
     wget \
     file \
     libssl-dev \
     libgtk-3-dev \
     libayatana-appindicator3-dev \
     librsvg2-dev
   ```

## ğŸš€ Quick Start

### 1. Clone and Install

```bash
cd voice-to-text-app
npm install
```

### 2. Configure API Key

The app will prompt you to enter your Deepgram API key on first launch. You can also:

1. Run the app in development mode
2. Click the settings icon (âš™ï¸) in the top right
3. Paste your Deepgram API key
4. Click "Save API Key"

The key is stored locally in your browser's localStorage.

### 3. Run Development Server

```bash
npm run tauri dev
```

This will:

- Start the Vite development server
- Launch the Tauri desktop application
- Enable hot-reload for rapid development

### 4. Build for Production

```bash
npm run tauri build
```

The built application will be in `src-tauri/target/release/`.

## ğŸ“– Usage

1. **Start the App**: Launch the application
2. **Configure**: Enter your Deepgram API key in settings (first time only)
3. **Record**: Hold down the large circular button
4. **Speak**: Talk naturally while holding the button
5. **Release**: Let go to stop recording
6. **View**: See your transcribed text appear in real-time
7. **Copy**: Click "Copy" to copy text to clipboard
8. **Clear**: Click "Clear" to start fresh

### Tips for Best Results

- Speak clearly at a normal pace
- Hold the button for the entire duration of your speech
- Use in a quiet environment for better accuracy
- The app shows interim results in gray (italic) while processing

## ğŸ—ï¸ Architecture

### Project Structure

```
voice-to-text-app/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ components/          # React UI components
â”‚   â”‚   â”œâ”€â”€ RecordButton.tsx      # Push-to-talk button
â”‚   â”‚   â”œâ”€â”€ RecordButton.css
â”‚   â”‚   â”œâ”€â”€ TranscriptDisplay.tsx # Text display area
â”‚   â”‚   â””â”€â”€ TranscriptDisplay.css
â”‚   â”œâ”€â”€ hooks/               # Custom React hooks
â”‚   â”‚   â””â”€â”€ useVoiceToText.ts    # Main voice-to-text logic
â”‚   â”œâ”€â”€ services/            # Core business logic
â”‚   â”‚   â”œâ”€â”€ audioService.ts      # Microphone & recording
â”‚   â”‚   â””â”€â”€ transcriptionService.ts  # Deepgram integration
â”‚   â”œâ”€â”€ App.tsx              # Main app component
â”‚   â”œâ”€â”€ App.css              # App styles
â”‚   â””â”€â”€ main.tsx             # Entry point
â”œâ”€â”€ src-tauri/               # Tauri backend (Rust)
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â””â”€â”€ lib.rs
â”‚   â”œâ”€â”€ Cargo.toml
â”‚   â””â”€â”€ tauri.conf.json
â”œâ”€â”€ package.json
â””â”€â”€ README.md
```

### Key Design Decisions

#### 1. **Separation of Concerns**

The codebase is organized into three distinct layers:

- **Services Layer** (`services/`): Pure business logic for audio and transcription

  - `audioService.ts`: Handles microphone access, audio capture, and streaming
  - `transcriptionService.ts`: Manages Deepgram API connection and transcription

- **Hooks Layer** (`hooks/`): React state management and service orchestration

  - `useVoiceToText.ts`: Coordinates audio recording and transcription services

- **Components Layer** (`components/`): UI presentation
  - Stateless, reusable components
  - Clear props interfaces

**Rationale**: This architecture makes the code testable, maintainable, and allows independent evolution of each layer.

#### 2. **Real-Time Streaming Architecture**

```
User Speech â†’ MediaRecorder â†’ Audio Chunks (250ms) â†’ Deepgram Live API â†’ Transcription Results
```

- **Chunked Audio Streaming**: MediaRecorder captures audio in 250ms chunks
- **WebSocket Connection**: Deepgram Live API for real-time processing
- **Interim Results**: Shows partial transcriptions before finalization

**Rationale**: Provides near-instant feedback to users, mimicking natural conversation flow.

#### 3. **Error Handling Strategy**

Three-tier error handling:

1. **Service Level**: Throws descriptive errors for specific failures
2. **Hook Level**: Catches errors and updates UI state
3. **Component Level**: Displays user-friendly error messages

Common error scenarios handled:

- Microphone permission denied
- No microphone found
- Network connectivity issues
- Invalid API key
- Deepgram API errors

**Rationale**: Graceful degradation ensures users understand what went wrong and how to fix it.

#### 4. **State Management**

Uses React hooks (`useState`, `useEffect`, `useCallback`) for:

- Recording state (idle, recording, processing, error)
- Transcript accumulation (final + interim)
- API key persistence (localStorage)

**Rationale**: Simple, performant state management without external dependencies for this scale of application.

## ğŸ”§ Configuration

### Audio Settings

Audio capture is configured for optimal Deepgram performance:

```typescript
{
  echoCancellation: true,     // Reduce echo
  noiseSuppression: true,     // Filter background noise
  sampleRate: 16000,          // 16kHz (Deepgram recommended)
}
```

### Deepgram Settings

```typescript
{
  model: 'nova-2',            // Latest, most accurate model
  language: 'en',             // English
  punctuate: true,            // Auto-punctuation
  interim_results: true,      // Real-time partial results
  smart_format: true,         // Better formatting
  encoding: 'linear16',       // Audio encoding
  sample_rate: 16000,         // Match audio capture
}
```

## ğŸ› Known Limitations

1. **Browser Compatibility**: Requires a modern browser for Web Audio API support
2. **Network Dependency**: Requires internet connection for Deepgram API
3. **Audio Format**: Uses WebM/Opus encoding (widely supported but not universal)
4. **Continuous Recording**: Hold-to-talk only; no voice activity detection
5. **Language Support**: Currently English only (easily extensible)
6. **No Offline Mode**: All transcription happens via Deepgram cloud API

## ğŸš¦ Testing

### Manual Testing Checklist

- [ ] Microphone permission request works
- [ ] Recording starts when button is pressed
- [ ] Recording stops when button is released
- [ ] Transcription appears in real-time
- [ ] Copy to clipboard works
- [ ] Clear transcript works
- [ ] Error messages display correctly
- [ ] API key persists across sessions
- [ ] App works on multiple platforms

### Testing Scenarios

1. **Happy Path**: Normal recording and transcription
2. **Permission Denied**: User denies microphone access
3. **No Microphone**: No audio input device available
4. **Network Error**: Offline or poor connection
5. **Invalid API Key**: Wrong or expired key
6. **Long Recording**: Extended speech (>1 minute)

## ğŸ” Security Considerations

- **API Key Storage**: Currently uses localStorage (browser storage)

  - âš ï¸ Not encrypted - suitable for development
  - For production: Consider using Tauri's secure storage or environment variables

- **HTTPS Required**: Microphone access requires secure context
  - Tauri automatically provides this
  - Web version requires HTTPS deployment

## ğŸ“ˆ Performance

- **Bundle Size**: ~5MB (significantly smaller than Electron alternatives)
- **Memory Usage**: ~80-150MB (depends on recording duration)
- **Latency**: ~500-1000ms from speech to transcription display
- **Audio Chunk Frequency**: 250ms (configurable)

## ğŸ”® Future Enhancements

Potential improvements for v2:

- [ ] Voice Activity Detection (VAD) - auto start/stop recording
- [ ] Multi-language support
- [ ] Custom keyboard shortcuts
- [ ] Text editing and formatting
- [ ] Export to file (TXT, DOCX, PDF)
- [ ] Integration with system clipboard
- [ ] Offline mode with local models
- [ ] Speaker diarization (multi-speaker)
- [ ] Encrypted API key storage
- [ ] Custom Deepgram model selection
- [ ] Audio playback functionality

## ğŸ“š Resources

- [Tauri Documentation](https://tauri.app/v1/guides/)
- [Deepgram API Docs](https://developers.deepgram.com/)
- [Web Audio API](https://developer.mozilla.org/en-US/docs/Web/API/Web_Audio_API)
- [MediaRecorder API](https://developer.mozilla.org/en-US/docs/Web/API/MediaRecorder)

## ğŸ¤ Contributing

This is a technical assignment project, but if you'd like to fork and extend:

1. Fork the repository
2. Create a feature branch (`git checkout -b feature/amazing-feature`)
3. Commit your changes (`git commit -m 'Add amazing feature'`)
4. Push to the branch (`git push origin feature/amazing-feature`)
5. Open a Pull Request

## ğŸ“ License

This project is created as a technical assignment. Use as you see fit.

## ğŸ‘¤ Author

Built as a practical demonstration of cross-platform AI-powered desktop application development skills.

## ğŸ™ Acknowledgments

- [Tauri Team](https://tauri.app/) - Amazing desktop framework
- [Deepgram](https://deepgram.com/) - Powerful speech recognition API
- [Wispr Flow](https://www.wispr.ai/) - Inspiration for this project

---

**Minimum Development Time Estimate**: 2-3 days for a competent developer

- Day 1: Setup, architecture, core services
- Day 2: UI components, integration, testing
- Day 3: Polish, documentation, edge cases

**With GitHub Copilot**: Can reduce development time by 30-40% through intelligent code suggestions and boilerplate generation.
